#!/usr/bin/env python3
"""
Generate research helper artifacts from Dhātu child prompts:
- docs/data/dhatu_child_phenomena_summary.md: table per language
- docs/data/dhatu_child_langs.md: languages with counts and external child sources

Run from repo root or from this folder.
"""
from __future__ import annotations
import os, json, sys
from collections import Counter

HERE = os.path.dirname(os.path.abspath(__file__))
REPO = os.path.abspath(os.path.join(HERE, "..", ".."))
DOCS_DATA = os.path.join(REPO, "docs", "data")

def load_child_prompts(lang_code: str):
    path = os.path.join(HERE, "prompts_child", f"{lang_code}.json")
    if not os.path.exists(path):
        return None
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def list_available_child_langs():
    base = os.path.join(HERE, "prompts_child")
    langs = []
    if os.path.isdir(base):
        for fn in os.listdir(base):
            if fn.endswith(".json") and fn not in ("schema.json",):
                langs.append(os.path.splitext(fn)[0])
    return sorted(langs)

def load_typological_sample():
    path = os.path.join(HERE, "typological_sample.json")
    if not os.path.exists(path):
        return {"languages": []}
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def find_lang_in_sample(sample, code):
    # try iso639_3 exact, then case-insensitive name match
    for lang in sample.get("languages", []):
        if lang.get("iso639_3") == code:
            return lang
    for lang in sample.get("languages", []):
        if str(lang.get("name", "")).lower() == code.lower():
            return lang
    return None

def ensure_docs_dir():
    os.makedirs(DOCS_DATA, exist_ok=True)

def write_markdown(path: str, content: str):
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)

def make_phenomena_summary_row(lc: str, items, cnt: Counter):
    distinct = len(cnt)
    top5 = ", ".join([f"{k} ({v})" for k, v in cnt.most_common(5)]) if cnt else ""
    src = f"experiments/dhatu/prompts_child/{lc}.json"
    return f"| `{lc}` | {items} | {distinct} | {top5} | `{src}` |\n"

def generate_phenomena_summary_md(langs):
    lines = []
    lines.append("<!-- Generated by experiments/dhatu/report.py -->\n")
    lines.append("### Synthèse phénomènes par langue (child prompts)\n\n")
    lines.append("| Lang | Items | Phénomènes distincts | Top 5 | Source |\n")
    lines.append("|:----:|------:|----------------------:|:------|:-------|\n")
    for lc in langs:
        data = load_child_prompts(lc)
        if not data:
            continue
        cnt = Counter()
        for it in data.get("items", []):
            for ph in it.get("phenomena", []):
                cnt[ph] += 1
        lines.append(make_phenomena_summary_row(lc, len(data.get("items", [])), cnt))
    return "".join(lines)

def generate_child_langs_md(langs, sample):
    lines = []
    lines.append("<!-- Generated by experiments/dhatu/report.py -->\n")
    lines.append("### Langues, volumes et sources enfant\n\n")
    lines.append("| Lang | Nom | Items | Sources enfant (externe) |\n")
    lines.append("|:----:|:-----|------:|:-------------------------|\n")
    for lc in langs:
        data = load_child_prompts(lc) or {}
        name = data.get("name") or data.get("lang", lc)
        n = len(data.get("items", []))
        lang_meta = find_lang_in_sample(sample, lc)
        sources_md = ""
        if lang_meta and lang_meta.get("child_sources"):
            parts = []
            for src in lang_meta["child_sources"]:
                title = src.get("name") or src.get("type")
                parts.append(f"[{title}]({src.get('url')})")
            sources_md = ", ".join(parts)
        lines.append(f"| `{lc}` | {name} | {n} | {sources_md} |\n")
    return "".join(lines)

def main():
    ensure_docs_dir()
    langs = list_available_child_langs()
    sample = load_typological_sample()
    ph_md = generate_phenomena_summary_md(langs)
    write_markdown(os.path.join(DOCS_DATA, "dhatu_child_phenomena_summary.md"), ph_md)
    langs_md = generate_child_langs_md(langs, sample)
    write_markdown(os.path.join(DOCS_DATA, "dhatu_child_langs.md"), langs_md)
    print("Generated: docs/data/dhatu_child_phenomena_summary.md")
    print("Generated: docs/data/dhatu_child_langs.md")

if __name__ == "__main__":
    sys.exit(main())
