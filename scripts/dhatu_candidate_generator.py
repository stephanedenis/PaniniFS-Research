#!/usr/bin/env python3
"""
G√©n√©rateur de DhƒÅtu Candidats pour PaniniFS
Analyse les gaps s√©mantiques et propose de nouveaux dhƒÅtu pour am√©liorer la couverture
"""

import json
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass
from collections import defaultdict
from semantic_coverage_analyzer import SemanticCoverageAnalyzer, SemanticGap

@dataclass
class DhatuCandidate:
    """Repr√©sente un candidat dhƒÅtu pour combler un gap s√©mantique"""
    name: str
    sanskrit_root: str
    concept_primitif: str
    semantic_category: str
    example_patterns: List[str]
    coverage_improvement: float  # Estimation du gain de couverture
    priority: int  # 1 = haute, 3 = basse

class DhatuCandidateGenerator:
    """G√©n√®re des candidats dhƒÅtu bas√©s sur l'analyse des gaps"""
    
    def __init__(self):
        self.analyzer = SemanticCoverageAnalyzer()
        
        # Mapping des cat√©gories de gaps vers des dhƒÅtu candidats
        self.gap_to_dhatu_mapping = {
            'Dimension √âmotionnelle/Qualitative': {
                'candidates': [
                    {
                        'name': 'EVAL',
                        'sanskrit_root': '‚àöman (penser, √©valuer)',
                        'concept': '√âvaluer qualitativement',
                        'patterns': ['√©l√©gant', 'beau', 'efficace', 'robuste', 'clean', 'elegant'],
                        'priority': 1
                    },
                    {
                        'name': 'FEEL',
                        'sanskrit_root': '‚àöbh≈´ (ressentir, √™tre)',
                        'concept': 'Ressentir √©motionnellement',
                        'patterns': ['aime', 'd√©teste', 'pr√©f√®re', 'love', 'hate', 'like'],
                        'priority': 2
                    }
                ]
            },
            'Dimension Causale/Temporelle': {
                'candidates': [
                    {
                        'name': 'CAUSE',
                        'sanskrit_root': '‚àönƒ´ (conduire, causer)',
                        'concept': 'Causer, provoquer',
                        'patterns': ['parce que', 'car', 'because', 'since', 'causes', 'results in'],
                        'priority': 1
                    },
                    {
                        'name': 'FLOW',
                        'sanskrit_root': '‚àögam (aller, s\'√©couler)',
                        'concept': 'Progresser temporellement',
                        'patterns': ['alors', 'puis', 'ensuite', 'then', 'after', 'timeline'],
                        'priority': 2
                    }
                ]
            },
            'Dimension Relationnelle/Contextuelle': {
                'candidates': [
                    {
                        'name': 'RELATE',
                        'sanskrit_root': '‚àöbandh (lier, relier)',
                        'concept': 'Mettre en relation',
                        'patterns': ['en relation avec', 'par rapport √†', 'relates to', 'compared to'],
                        'priority': 1
                    },
                    {
                        'name': 'CONTRAST',
                        'sanskrit_root': '‚àöv·πõt (tourner, opposer)',
                        'concept': 'Contraster, opposer',
                        'patterns': ['oppos√©', 'versus', 'par opposition', 'contrary to', 'different'],
                        'priority': 2
                    }
                ]
            },
            'Dimension Existentielle/Ontologique': {
                'candidates': [
                    {
                        'name': 'EXIST',
                        'sanskrit_root': '‚àöas (√™tre, exister)',
                        'concept': 'Exister, √™tre pr√©sent',
                        'patterns': ['existe', 'il y a', 'exists', 'there is', 'being', 'reality'],
                        'priority': 1
                    },
                    {
                        'name': 'MODAL',
                        'sanskrit_root': '‚àö≈õak (pouvoir, √™tre capable)',
                        'concept': 'Modalit√© (possible/probable)',
                        'patterns': ['peut-√™tre', 'possible', 'might', 'could', 'maybe', 'potential'],
                        'priority': 2
                    }
                ]
            },
            'Dimension Temporelle Complexe': {
                'candidates': [
                    {
                        'name': 'SYNC',
                        'sanskrit_root': '‚àöyuj (joindre, synchroniser)',
                        'concept': 'Synchroniser temporellement',
                        'patterns': ['pendant', 'en m√™me temps', 'while', 'during', 'simultaneously'],
                        'priority': 2
                    }
                ]
            },
            'Dimension Spatiale/G√©om√©trique': {
                'candidates': [
                    {
                        'name': 'POSITION',
                        'sanskrit_root': '‚àösthƒÅ (se tenir, positionner)',
                        'concept': 'Positionner spatialement',
                        'patterns': ['au-dessus', 'dedans', 'pr√®s de', 'above', 'inside', 'near'],
                        'priority': 3
                    }
                ]
            }
        }
    
    def analyze_corpus_for_gaps(self, texts: List[str]) -> Dict:
        """Analyse un corpus pour identifier les gaps s√©mantiques principaux"""
        
        all_gaps = []
        gap_frequency = defaultdict(int)
        gap_examples = defaultdict(list)
        
        print(f"üîç Analyse de {len(texts)} textes pour identifier les gaps...")
        
        for text in texts:
            result = self.analyzer.analyze_text(text)
            
            for gap in result['semantic_gaps']:
                all_gaps.append(gap)
                gap_frequency[gap.semantic_category] += 1
                gap_examples[gap.semantic_category].append(gap.text_fragment)
        
        # Trier par fr√©quence pour identifier les gaps prioritaires
        sorted_gaps = sorted(gap_frequency.items(), key=lambda x: x[1], reverse=True)
        
        return {
            'total_gaps': len(all_gaps),
            'gap_frequency': dict(gap_frequency),
            'gap_examples': {k: list(set(v)) for k, v in gap_examples.items()},
            'priority_order': sorted_gaps,
            'analysis_summary': self._generate_gap_analysis_summary(sorted_gaps, len(texts))
        }
    
    def generate_dhatu_candidates(self, gap_analysis: Dict) -> List[DhatuCandidate]:
        """G√©n√®re une liste de candidats dhƒÅtu bas√©e sur l'analyse des gaps"""
        
        candidates = []
        
        for gap_category, frequency in gap_analysis['priority_order']:
            if gap_category in self.gap_to_dhatu_mapping:
                category_candidates = self.gap_to_dhatu_mapping[gap_category]['candidates']
                
                for candidate_info in category_candidates:
                    # Calcul de l'am√©lioration de couverture estim√©e
                    coverage_improvement = self._estimate_coverage_improvement(
                        frequency, len(gap_analysis['gap_examples'][gap_category])
                    )
                    
                    candidate = DhatuCandidate(
                        name=candidate_info['name'],
                        sanskrit_root=candidate_info['sanskrit_root'],
                        concept_primitif=candidate_info['concept'],
                        semantic_category=gap_category,
                        example_patterns=candidate_info['patterns'],
                        coverage_improvement=coverage_improvement,
                        priority=candidate_info['priority']
                    )
                    
                    candidates.append(candidate)
        
        # Trier par priorit√© et am√©lioration de couverture
        candidates.sort(key=lambda x: (x.priority, -x.coverage_improvement))
        
        return candidates
    
    def _estimate_coverage_improvement(self, frequency: int, unique_examples: int) -> float:
        """Estime l'am√©lioration de couverture qu'apporterait un nouveau dhƒÅtu"""
        # Formule simple : fr√©quence * diversit√© des exemples / 100
        return min((frequency * unique_examples) / 10.0, 25.0)  # Max 25% d'am√©lioration
    
    def _generate_gap_analysis_summary(self, sorted_gaps: List[Tuple], total_texts: int) -> Dict:
        """G√©n√®re un r√©sum√© de l'analyse des gaps"""
        
        if not sorted_gaps:
            return {'message': 'Aucun gap s√©mantique identifi√©', 'recommendation': 'Les 7 dhƒÅtu actuels sont suffisants'}
        
        top_gap = sorted_gaps[0]
        total_gap_instances = sum(freq for _, freq in sorted_gaps)
        
        return {
            'main_gap_category': top_gap[0],
            'main_gap_frequency': top_gap[1],
            'gap_density': round(total_gap_instances / total_texts, 2),
            'categories_affected': len(sorted_gaps),
            'recommendation': self._get_recommendation(total_gap_instances, total_texts)
        }
    
    def _get_recommendation(self, total_gaps: int, total_texts: int) -> str:
        """G√©n√®re une recommandation bas√©e sur la densit√© des gaps"""
        density = total_gaps / total_texts
        
        if density > 2:
            return "Gaps s√©mantiques √©lev√©s : ajout de nouveaux dhƒÅtu fortement recommand√©"
        elif density > 1:
            return "Gaps mod√©r√©s : consid√©rer l'ajout de 2-3 nouveaux dhƒÅtu prioritaires"
        elif density > 0.5:
            return "Gaps faibles : √©valuer l'ajout de 1-2 dhƒÅtu sp√©cialis√©s"
        else:
            return "Gaps n√©gligeables : les dhƒÅtu actuels sont largement suffisants"
    
    def optimize_dhatu_set(self, current_dhatu: List[str], candidates: List[DhatuCandidate], 
                          target_coverage: float = 85.0) -> Dict:
        """Optimise le set de dhƒÅtu pour atteindre la couverture cible"""
        
        # Simulation d'optimisation (approche greedy)
        optimized_set = current_dhatu.copy()
        coverage_improvement = 0.0
        added_dhatu = []
        
        # Trier les candidats par rapport am√©lioration/priorit√©
        sorted_candidates = sorted(candidates, 
                                 key=lambda x: (-x.coverage_improvement, x.priority))
        
        current_coverage = 66.7  # Score de base observ√©
        
        for candidate in sorted_candidates:
            projected_coverage = current_coverage + candidate.coverage_improvement
            
            if projected_coverage <= target_coverage and len(optimized_set) < 15:  # Limite √† 15 dhƒÅtu max
                optimized_set.append(candidate.name)
                added_dhatu.append(candidate)
                current_coverage = projected_coverage
                coverage_improvement += candidate.coverage_improvement
                
                if current_coverage >= target_coverage:
                    break
        
        return {
            'optimized_dhatu_set': optimized_set,
            'added_dhatu': [d.name for d in added_dhatu],
            'projected_coverage': round(current_coverage, 2),
            'improvement': round(coverage_improvement, 2),
            'total_dhatu_count': len(optimized_set),
            'efficiency_ratio': round(current_coverage / len(optimized_set), 2)
        }

def main():
    """Fonction de test et d√©monstration"""
    generator = DhatuCandidateGenerator()
    
    # Corpus de test √©tendu pour identifier les gaps
    test_corpus = [
        "I love this elegant solution because it efficiently transforms data",
        "Cette approche est robuste car elle g√®re bien les cas d'erreur",
        "The algorithm exists to solve the problem, but it might sometimes fail",
        "En relation avec notre discussion, ce code est plus lisible",
        "Cette fonction est belle et efficace compar√©e √† l'ancienne version",
        "Le syst√®me pourrait √™tre am√©lior√© si nous ajoutons cette fonctionnalit√©",
        "Par opposition aux autres solutions, celle-ci est plus maintenable",
        "Il y a plusieurs fa√ßons d'impl√©menter cela, mais cette approche est pr√©f√©rable",
        "Pendant que le processus s'ex√©cute, nous pouvons faire autre chose",
        "Cette m√©thode fonctionne bien parce qu'elle suit les bonnes pratiques"
    ]
    
    print("üß¨ G√âN√âRATEUR DE DHƒÄTU CANDIDATS")
    print("=" * 50)
    
    # √âtape 1: Analyser les gaps dans le corpus
    print("\nüìä ANALYSE DES GAPS S√âMANTIQUES")
    gap_analysis = generator.analyze_corpus_for_gaps(test_corpus)
    
    print(f"Total gaps identifi√©s: {gap_analysis['total_gaps']}")
    print(f"Cat√©gories affect√©es: {len(gap_analysis['gap_frequency'])}")
    print(f"Densit√© de gaps: {gap_analysis['analysis_summary']['gap_density']}")
    
    print("\nüéØ Gaps prioritaires:")
    for category, freq in gap_analysis['priority_order'][:3]:
        print(f"  ‚Ä¢ {category}: {freq} occurrences")
        examples = gap_analysis['gap_examples'][category][:3]
        print(f"    Exemples: {', '.join(examples)}")
    
    # √âtape 2: G√©n√©rer les candidats dhƒÅtu
    print("\nüî¨ CANDIDATS DHƒÄTU PROPOS√âS")
    candidates = generator.generate_dhatu_candidates(gap_analysis)
    
    for i, candidate in enumerate(candidates[:5], 1):  # Top 5
        print(f"\n{i}. **{candidate.name}** ({candidate.sanskrit_root})")
        print(f"   Concept: {candidate.concept_primitif}")
        print(f"   Cat√©gorie: {candidate.semantic_category}")
        print(f"   Am√©lioration estim√©e: +{candidate.coverage_improvement:.1f}%")
        print(f"   Priorit√©: {candidate.priority}/3")
    
    # √âtape 3: Optimisation du set complet
    print("\n‚ö° OPTIMISATION DU SET DHƒÄTU")
    current_dhatu = ['COMM', 'ITER', 'TRANS', 'DECIDE', 'LOCATE', 'GROUP', 'SEQ']
    optimization = generator.optimize_dhatu_set(current_dhatu, candidates, target_coverage=85.0)
    
    print(f"Set actuel ({len(current_dhatu)} dhƒÅtu): {', '.join(current_dhatu)}")
    print(f"Set optimis√© ({optimization['total_dhatu_count']} dhƒÅtu): {', '.join(optimization['optimized_dhatu_set'])}")
    print(f"Nouveaux dhƒÅtu ajout√©s: {', '.join(optimization['added_dhatu'])}")
    print(f"Couverture projet√©e: {optimization['projected_coverage']}% (+{optimization['improvement']}%)")
    print(f"Efficacit√©: {optimization['efficiency_ratio']}% par dhƒÅtu")
    
    print(f"\n‚úÖ Recommandation: {gap_analysis['analysis_summary']['recommendation']}")

if __name__ == "__main__":
    main()
